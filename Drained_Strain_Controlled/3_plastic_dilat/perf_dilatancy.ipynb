{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Elasto-Plastic with Dilatancy MC models\n",
    "\n",
    "#### Author: Jonathan Moore\n",
    "\n",
    "#### Purpose:\n",
    "The purpose of this notebook is to run the incremental driver models with elasto-plastic  MC with dilatancy and then generate the associated plots.\n",
    "Plots are:\n",
    "* Quad Plot\n",
    "* Error vs. Strain (Relative Error)\n",
    "* 2-Norm error (standard eucliedean error) vs. Compute time\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules and make define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"/mnt/data/the_deep/Geotech_Research/Critical_Soil_Models/pumat\")\n",
    "\n",
    "from lib.Load_Classes.Popular_Load_Class import PopularPath\n",
    "from lib.Driver_Classes.Mod_Driver_Setup import DriverModelSetup\n",
    "from lib.Driver_Classes.Mod_Driver_Model import DriverModel\n",
    "from lib.general_functions.executing_runs import generate_batch_script, run_batch_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def get_model_times(model_list, max_iters):\n",
    "    model_times = []\n",
    "\n",
    "    # Create a df with the number of loads as a header\n",
    "    for model in model_list:\n",
    "        i = 0\n",
    "        while i < max_iters:\n",
    "            start_time = time.time()\n",
    "            model.run_model()\n",
    "            end_time = time.time()\n",
    "\n",
    "            elasped_time = end_time - start_time\n",
    "            model_times.append(elasped_time)\n",
    "            \n",
    "            # Increment the counter\n",
    "            i = i + 1\n",
    "\n",
    "    return model_times\n",
    "\n",
    "def calc_error(measured_val, true_val, error_type = \"abs\"):\n",
    "    \"\"\" Calculates different types of error between a measured value and a true value\"\"\"\n",
    "\n",
    "    match error_type:\n",
    "        case \"2norm\":\n",
    "            error = np.linalg.norm(measured_val - true_val)\n",
    "        case \"relative\":\n",
    "            # Calc the decimal percent error for each term\n",
    "            error = np.abs( (measured_val - true_val) / true_val )\n",
    "        case \"abs\":\n",
    "            error = np.abs(measured_val - true_val)\n",
    "        case \"max_abs\":\n",
    "            error = np.max(np.abs(measured_val - true_val))\n",
    "        case \"mean_abs\":\n",
    "            error = np.mean(np.abs(measured_val - true_val))\n",
    "        case _:\n",
    "            raise ValueError(\"Error type not recognised\")\n",
    "\n",
    "    return error\n",
    "\n",
    "def calc_k0(phi):\n",
    "    \"\"\"Calc the k0 value for a given phi using the relationship from (TODO: Add reference)\"\"\"\n",
    "    return 1 - np.sin(phi)\n",
    "\n",
    "\n",
    "def interp_data(interp_strain_vals, model_strain_data, model_value_data):\n",
    "    \"\"\"Function to interpolate data from a model to a new set of strain values\"\"\"\n",
    "    \n",
    "    model_strain_data = np.abs( model_strain_data )\n",
    "\n",
    "    if not np.all(np.diff(interp_strain_vals) > 0):\n",
    "        raise ValueError(\"Strain data must be in increasing order\")\n",
    "    \n",
    "    # interpolate the values\n",
    "    value = np.interp(interp_strain_vals, model_strain_data , model_value_data)\n",
    "\n",
    "    # Return the interpolated values    \n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the material and initial conditions for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the friction angle from degrees to radians\n",
    "# Setting the friction angle so it corresponds to a stress ratio of approx 1.0\n",
    "phi = 25.4 * np.pi/180#25.375 * np.pi/180\n",
    "stress_ratio = 6 * np.sin(phi)/(3 - np.sin(phi))\n",
    "\n",
    "k0 = calc_k0(phi)\n",
    "\n",
    "print(f\"Stress ratio: {stress_ratio:.2}\")\n",
    "print(f\"k0: {k0:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit weight\n",
    "# Calculating the unit weight to see the loads that occur at \n",
    "\n",
    "# Calc the unit weight assuming a porosity of 0.45\n",
    "porosity = 0.45\n",
    "particle_density = 2650.0 #[kg/m^3]\n",
    "unit_weight = (1 - porosity) * particle_density * 9.81 #[N/m^3]\n",
    "\n",
    "\n",
    "# Assume a depth of 1m and calc the vertical stress\n",
    "vert_stress = unit_weight * 1\n",
    "\n",
    "print(f\"Unit weight: {unit_weight:.2f} N/m^3\")\n",
    "print(f\"Vertical Stress at 1m depth: {vert_stress/1000:.2f} kN/m^2 (kPa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be in the order that the parameters should be in\n",
    "\n",
    "initial_fric_angle = 25.375\n",
    "initial_cohesion = 0\n",
    "sub_properties = {\n",
    "    \"Shear Modulus (kPa)\"    : 2500,\n",
    "    \"poisson ratio\"          : 0.2,\n",
    "    \"peak cohesion\"          : initial_cohesion,\n",
    "    \"residual cohesion\"      : 0,\n",
    "    \"peak fric angle\"        : initial_fric_angle,\n",
    "    \"residual fric angle\"    : 0,\n",
    "    \"peak dilatancy\"         : 15, \n",
    "    \"residual dilatancy\"     : 15,\n",
    "    \"softening shape factor\" : 0,\n",
    "    \"integration flag\"       : 0, # zero for substepping, 1 for Ortiz-Simo\n",
    "    \"Yield surface tolerance\": 1e-8,\n",
    "    \"num integration iters\"  : 1000,\n",
    "    \"Euler_DT_min\"           : 1e-8 # minimum pseudo time step for sloan integration\n",
    "}\n",
    "\n",
    "# Set the ortiz properties to be the same as the newton properties except change the integration flag to be 1\n",
    "ortiz_properties = sub_properties.copy()\n",
    "ortiz_properties[\"integration flag\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the folders for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the current folder\n",
    "current_working_dir = os.getcwd()\n",
    "\n",
    "# Path to the folder that the Ortiz-Simo data should be stored in\n",
    "Ortiz_folder = os.path.join(current_working_dir, \"Ortiz_Simo\")\n",
    "\n",
    "# Path to the folder that the Newton Raphson data should be stored in\n",
    "Newton_folder = os.path.join(current_working_dir, \"Sloan_Abbo\")\n",
    "\n",
    "exe_path = r\"/mnt/data/the_deep/Geotech_Research/Critical_Soil_Models/MohrCoulomb_StrainSoft/build/gfortran_E167FD2A985B468F/app/MCSS_incrementalDriver\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OS_models = [\n",
    "          DriverModel(os.path.join(current_working_dir, \"Ortiz_Simo_500_ninc\"), \"Ortiz_MCSS\", exe_path, \"output.txt\"),\n",
    "          DriverModel(os.path.join(current_working_dir, \"Ortiz_Simo_1000_ninc\"), \"Ortiz_MCSS\", exe_path, \"output.txt\"),\n",
    "          DriverModel(os.path.join(current_working_dir, \"Ortiz_Simo_5000_ninc\"), \"Ortiz_MCSS\", exe_path, \"output.txt\"),\n",
    "]\n",
    "\n",
    "Sub_models = [\n",
    "          DriverModel(os.path.join(current_working_dir, \"Sloan_Abbo_500_ninc\"), \"Sloan_Abbo\", exe_path, \"output.txt\"),\n",
    "          DriverModel(os.path.join(current_working_dir, \"Sloan_Abbo_1000_ninc\"), \"Sloan_Abbo\", exe_path, \"output.txt\"),\n",
    "          DriverModel(os.path.join(current_working_dir, \"Sloan_Abbo_5000_ninc\"), \"Sloan_Abbo\", exe_path, \"output.txt\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the colors that will be used for plotting the model results later\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(OS_models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in OS_models:\n",
    "    model.setup.clear_folder()\n",
    "    \n",
    "for model in Sub_models:\n",
    "    model.setup.clear_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the model objects and make the input files for Incremental Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_strain = \"TriaxialE1\"\n",
    "\n",
    "nincs = [500, 1000, 5000] # Number of incremental steps to use\n",
    "\n",
    "init_stress = -10 # Initial stress in kPa\n",
    "\n",
    "# Set the stress and state parameters\n",
    "stress = np.array([init_stress, k0 * init_stress, k0 * init_stress, 0, 0, 0])\n",
    "state_params = {\"cohesion\": 0,\n",
    "                \"fric angle\": initial_fric_angle * np.pi/180,\n",
    "                \"dilatancy angle\": 0,\n",
    "                \"EspP_1\": 0,\n",
    "                \"EspP_2\": 0,\n",
    "                \"EspP_3\": 0,\n",
    "                \"EspP_4\": 0,\n",
    "                \"EspP_5\": 0,\n",
    "                \"EspP_6\": 0\n",
    "}\n",
    "\n",
    "load_params = {\n",
    "        \"ninc\"   : None,\n",
    "        \"maxiter\": 100,\n",
    "        \"dtime\"  : 500_000,\n",
    "        \"every\"  : 1,\n",
    "        \"ddstran_1\": -0.4,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create the substepping models\n",
    "for inc, model in zip(nincs, Sub_models):\n",
    "    # Set the number of strain increments\n",
    "    temp_load_params = load_params.copy()\n",
    "    temp_load_params[\"ninc\"] = inc\n",
    "    temp_load = PopularPath(trx_strain, temp_load_params)\n",
    "\n",
    "    # Write the load parameters\n",
    "    model.setup.write_initial_conditions_file(stress, state_params)\n",
    "    # Clear the old loads\n",
    "    model.setup.delete_all_loads()\n",
    "    \n",
    "    # Store the new loads\n",
    "    model.setup.store_loads(temp_load)\n",
    "    model.setup.write_loads()\n",
    "    model.setup.write_parameters_file(sub_properties)\n",
    "\n",
    "# Generate the OS models\n",
    "for inc, model in zip(nincs, OS_models):\n",
    "    # Set the number of strain increments\n",
    "    temp_load_params = load_params.copy()\n",
    "    temp_load_params[\"ninc\"] = inc\n",
    "    temp_load = PopularPath(trx_strain, temp_load_params)\n",
    "\n",
    "    # Write the load parameters\n",
    "    model.setup.write_initial_conditions_file(stress, state_params)\n",
    "    \n",
    "    # Clear the old loads\n",
    "    model.setup.delete_all_loads()\n",
    "    # Store the new load\n",
    "    model.setup.store_loads(temp_load)\n",
    "    model.setup.write_loads()\n",
    "    model.setup.write_parameters_file(ortiz_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS_times = []\n",
    "max_iters = 10\n",
    "\n",
    "OS_times = get_model_times(OS_models, max_iters)\n",
    "print(\"\")\n",
    "Sub_times = get_model_times(Sub_models, max_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing the computational time per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average time for each model\n",
    "OS_avg_time = [None] * len(OS_models)\n",
    "Sub_avg_time = [None] * len(Sub_models)\n",
    "\n",
    "for i, model in enumerate(OS_models):\n",
    "    OS_avg_time[i] = np.mean(OS_times[i*max_iters:(i+1)*max_iters])\n",
    "\n",
    "for i, model in enumerate(Sub_models):\n",
    "    Sub_avg_time[i] = np.mean(Sub_times[i*max_iters:(i+1)*max_iters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(OS_times , color = colors[0], label=\"Ortiz-Simo\")\n",
    "plt.plot(Sub_times, color = colors[1], label=\"Sloan-Abbo\")\n",
    "\n",
    "avg_times = [max_iters/2, max_iters/2 + max_iters, max_iters/2 + 2 * max_iters]\n",
    "\n",
    "# Plot the average times\n",
    "plt.plot(avg_times, OS_avg_time, color = colors[0], marker = \".\")\n",
    "plt.plot(avg_times, Sub_avg_time, color = colors[1], marker = \".\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremental Driver is doing something strange at the start of the calculations so I'm removing that from the error analysis\n",
    "val = 10\n",
    "\n",
    "for model in OS_models:\n",
    "    model.results.store_all()\n",
    "\n",
    "for model in Sub_models:\n",
    "    model.results.store_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OS_models[-1].setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the correct model to be the Substepping model with the highest iterations\n",
    "correct_model = Sub_models[-1]\n",
    "\n",
    "print(correct_model.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the model errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init lists to hold the errors\n",
    "OS_q_error = []\n",
    "OS_p_error = []\n",
    "OS_eps_v = []\n",
    "\n",
    "\n",
    "OS_errors = {\n",
    "    \"q_error\": [],\n",
    "    \"p_error\": [],\n",
    "    \"eps_v_error\": [],\n",
    "    \"eps_q_error\":[]\n",
    "}\n",
    "\n",
    "\n",
    "Sub_errors = {\n",
    "    \"q_error\": [],\n",
    "    \"p_error\": [],\n",
    "    \"eps_v_error\": [],\n",
    "    \"eps_q_error\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "\n",
    "for model in OS_models:\n",
    "\n",
    "    # Get the length of the \n",
    "    # Calc the (q) error\n",
    "\n",
    "    # Get the strain values that the function should be evaluated at and take the abs value because interp function needs to be in increasing order\n",
    "    correct_model_strain = np.abs( correct_model.results.strain_df[\"stran(1)\"] )\n",
    "\n",
    "    model_strain= np.abs( model.results.strain_df[\"stran(1)\"] )\n",
    "    \n",
    "    # Interpolate the q invariant\n",
    "    q_interp = interp_data(correct_model_strain, model_strain, model.results.get_q_invariant())\n",
    "    \n",
    "    OS_errors[\"q_error\"].append(calc_error(q_interp, correct_model.results.get_q_invariant(), error_type=\"abs\"))\n",
    "\n",
    "    # Calc the p error\n",
    "    # Interpolate the p invariant\n",
    "    p_interp = interp_data(correct_model_strain, model_strain, model.results.get_mean_stress())\n",
    "    \n",
    "    OS_errors[\"p_error\"].append(calc_error(p_interp, correct_model.results.get_mean_stress(), error_type=\"abs\"))\n",
    "\n",
    "    # eps_v error\n",
    "    # Interpolate the volumetric strain\n",
    "    eps_v_interp = interp_data(correct_model_strain, model_strain, model.results.get_volumetric_strain())\n",
    "    OS_errors[\"eps_v_error\"].append(calc_error(eps_v_interp, correct_model.results.get_volumetric_strain(), error_type=\"abs\"))\n",
    "\n",
    "    eps_q_interp = interp_data(correct_model_strain, model_strain, model.results.get_deviatoric_strain())\n",
    "    OS_errors[\"eps_q_error\"].append(calc_error(eps_q_interp, correct_model.results.get_deviatoric_strain(), error_type=\"abs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in Sub_models:\n",
    "\n",
    "    # Get the length of the \n",
    "    # Calc the (q) error\n",
    "\n",
    "    # Get the strain values that the function should be evaluated at and take the abs value because interp function needs to be in increasing order\n",
    "    correct_model_strain = np.abs( correct_model.results.strain_df[\"stran(1)\"] )\n",
    "\n",
    "    model_strain= np.abs( model.results.strain_df[\"stran(1)\"] )\n",
    "    \n",
    "    # Interpolate the q invariant\n",
    "    q_interp = interp_data(correct_model_strain, model_strain, model.results.get_q_invariant())\n",
    "    \n",
    "    Sub_errors[\"q_error\"].append(calc_error(q_interp, correct_model.results.get_q_invariant(), error_type=\"abs\"))\n",
    "\n",
    "    # Calc the p error\n",
    "    # Interpolate the p invariant\n",
    "    p_interp = interp_data(correct_model_strain, model_strain, model.results.get_mean_stress())\n",
    "    Sub_errors[\"p_error\"].append(calc_error(p_interp, correct_model.results.get_mean_stress(), error_type=\"abs\"))\n",
    "    # eps_v error\n",
    "    # Interpolate the volumetric strain\n",
    "    eps_v_interp = interp_data(correct_model_strain, model_strain, model.results.get_volumetric_strain())\n",
    "    \n",
    "    Sub_errors[\"eps_v_error\"].append(calc_error(eps_v_interp, correct_model.results.get_volumetric_strain(), error_type=\"abs\"))\n",
    "    \n",
    "    eps_q_interp = interp_data(correct_model_strain, model_strain, model.results.get_deviatoric_strain())\n",
    "    Sub_errors[\"eps_q_error\"].append(calc_error(eps_q_interp, correct_model.results.get_deviatoric_strain(), error_type=\"abs\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OS_max_abs_errors = {\n",
    "    \"stress_error\": [],\n",
    "    \"strain_error\": []\n",
    "}\n",
    "\n",
    "for model in OS_models:\n",
    "    # Interpolate the stress data\n",
    "    stress_df = model.results.stress_df.copy()\n",
    "    strain_df = model.results.strain_df.copy()\n",
    "\n",
    "    stress_df_interp = pd.DataFrame()\n",
    "    strain_df_interp = pd.DataFrame()\n",
    "    \n",
    "    x = np.linspace(0, 1, len(stress_df))\n",
    "    new_x = np.linspace(0, 1, len(correct_model.results.stress_df))\n",
    "\n",
    "    for col in stress_df.columns:\n",
    "        interp_func = interp1d(x, stress_df[col], kind=\"linear\")\n",
    "        \n",
    "        new_y = interp_func(new_x)\n",
    "        stress_df_interp[col] = new_y\n",
    "\n",
    "    for col in strain_df.columns:\n",
    "        interp_func = interp1d(x, strain_df[col], kind=\"linear\")\n",
    "\n",
    "        new_y = interp_func(new_x)\n",
    "        strain_df_interp[col] = new_y\n",
    "    \n",
    "    OS_max_abs_errors[\"stress_error\"].append(calc_error(stress_df_interp[val:], correct_model.results.stress_df[val:], \"max_abs\"))\n",
    "    \n",
    "    OS_max_abs_errors[\"strain_error\"].append(calc_error(strain_df_interp[val:], correct_model.results.strain_df[val:], \"max_abs\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a for the Substepping model\n",
    "Sub_max_abs_errors = {\n",
    "    \"stress_error\": [],\n",
    "    \"strain_error\": []\n",
    "}\n",
    "for model in Sub_models:\n",
    "    # Interpolate the stress data\n",
    "    stress_df = model.results.stress_df.copy()\n",
    "    strain_df = model.results.strain_df.copy()\n",
    "\n",
    "    stress_df_interp = pd.DataFrame()\n",
    "    strain_df_interp = pd.DataFrame()\n",
    "    \n",
    "    x = np.linspace(0, 1, len(stress_df))\n",
    "    new_x = np.linspace(0, 1, len(correct_model.results.stress_df))\n",
    "\n",
    "    for col in stress_df.columns:\n",
    "        interp_func = interp1d(x, stress_df[col], kind=\"linear\")\n",
    "        \n",
    "        new_y = interp_func(new_x)\n",
    "        stress_df_interp[col] = new_y\n",
    "\n",
    "    for col in strain_df.columns:\n",
    "        interp_func = interp1d(x, strain_df[col], kind=\"linear\")\n",
    "\n",
    "        new_y = interp_func(new_x)\n",
    "        strain_df_interp[col] = new_y\n",
    "    \n",
    "    Sub_max_abs_errors[\"stress_error\"].append(calc_error(stress_df_interp[val:], correct_model.results.stress_df[val:], \"max_abs\"))\n",
    "    \n",
    "    Sub_max_abs_errors[\"strain_error\"].append(calc_error(strain_df_interp[val:], correct_model.results.strain_df[val:], \"max_abs\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global error vs. computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (8, 3), dpi = 300)\n",
    "\n",
    "error_names = [\"stress_error\", \"strain_error\"]\n",
    "\n",
    "\n",
    "for i, error_name in enumerate(error_names):\n",
    "    \n",
    "    # Get the error\n",
    "    OS_error = OS_max_abs_errors[error_name]\n",
    "    Sub_error = Sub_max_abs_errors[error_name]\n",
    "\n",
    "    color_index = 0\n",
    "    # Plot the error\n",
    "    axs[i].plot(OS_avg_time, OS_error, label = \"OS\", marker = \".\", color = colors[color_index])\n",
    "    axs[i].plot(Sub_avg_time, Sub_error, label = \"Sloan-Abbo\", marker = \".\", linestyle = \"dashed\", color = colors[color_index])\n",
    "\n",
    "\n",
    "# Format the first plot\n",
    "axs[0].set_xlabel(\"Average Compute Time [s]\")\n",
    "axs[0].set_ylabel(\" Max Abs. Error [kPa]\")\n",
    "axs[0].set_title(\"Stress Tensor Error\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Format the second plot\n",
    "axs[1].set_title(\"Strain Tensor Error\")\n",
    "axs[1].set_xlabel(\"Average Compute Time [s]\")\n",
    "# axs[1].set_ylabel(\"Max Abs Strain Error [-]\")\n",
    "\n",
    "\n",
    "image_name = \"Drained_Strain_Control_plastic_dilat_tensor_error.pdf\"\n",
    "mcss_latex_folder = \"/home/jmoore/Documents/Master_Thesis/chapters/Constitutive_Modelling/mcss_images/plastic_dilat\"\n",
    "save_fig_path = os.path.join(mcss_latex_folder, image_name)\n",
    "fig.savefig(save_fig_path, format = \"pdf\", bbox_inches = 'tight')\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absoloute Error vs Strain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(OS_errors[\"q_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 4, figsize = (15, 5), dpi = 300)\n",
    "\n",
    "error_names = [\"q_error\", \"p_error\", \"eps_v_error\", \"eps_q_error\"]\n",
    "\n",
    "for i, model in enumerate(OS_models):\n",
    "            # Get the model name\n",
    "    folder_name = os.path.basename(model.setup.folder_path)\n",
    "    num_iters = re.search(r'\\d+', folder_name).group()\n",
    "\n",
    "    name = f\"Ortiz-Simo  {num_iters} iters\"\n",
    "\n",
    "    # Loop over the error names\n",
    "    for j, error_name in enumerate(error_names):\n",
    "        \n",
    "        error = OS_errors[error_name][i]\n",
    " \n",
    "        # Plot the error versus the strain\n",
    "        fig.axes[j].plot(correct_model_strain, error, label = name, color = colors[i])\n",
    "        \n",
    "        if j ==0:\n",
    "           fig.axes[j].legend()\n",
    "\n",
    "# Format the plot\n",
    "fig.suptitle(\"Ortiz-Simo Error vs Strain\")\n",
    "axs[0].set_title(\"q Error\")\n",
    "axs[0].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "axs[0].set_ylabel(\"Absolute Error\")\n",
    "\n",
    "axs[1].set_title(\"p Error\")\n",
    "axs[1].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "\n",
    "\n",
    "axs[2].set_title(\"$\\\\epsilon_{v}$ Error\")\n",
    "axs[2].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "\n",
    "axs[3].set_title(\"$\\\\epsilon_{q}$ Error\")\n",
    "axs[3].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "\n",
    "# image_name = \"Drained_Strain_Control_perf_plastic_OS_strain_error.pdf\"\n",
    "# mcss_latex_folder = \"/home/jmoore/Documents/Master_Thesis/chapters/Constitutive_Modelling/mcss_images\"\n",
    "# save_fig_path = os.path.join(mcss_latex_folder, image_name)\n",
    "# fig.savefig(save_fig_path, format = \"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 4, figsize = (15, 5), dpi = 300)\n",
    "\n",
    "error_names = [\"q_error\", \"p_error\", \"eps_v_error\", \"eps_q_error\"]\n",
    "\n",
    "for i, model in enumerate(Sub_models):\n",
    "            # Get the model name\n",
    "    folder_name = os.path.basename(model.setup.folder_path)\n",
    "    num_iters = re.search(r'\\d+', folder_name).group()\n",
    "\n",
    "    name = f\"Sloan-Abbo  {num_iters} iters\"\n",
    "\n",
    "    # Loop over the error names\n",
    "    for j, error_name in enumerate(error_names):\n",
    "        \n",
    "        error = Sub_errors[error_name][i]\n",
    "        \n",
    "        # Plot the error versus the strain\n",
    "        fig.axes[j].plot(correct_model_strain, error, label = name, color = colors[i])\n",
    "\n",
    "        fig.axes[j].legend()\n",
    "\n",
    "# Format the plot\n",
    "fig.suptitle(\"Sloan-Abbo Absolute Error\")\n",
    "axs[0].set_title(\"q Error\")\n",
    "axs[0].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "axs[0].set_ylabel(\"Absolute Error\")\n",
    "\n",
    "axs[1].set_title(\"p Error\")\n",
    "axs[1].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "axs[0].set_ylabel(\"Absolute Error\")\n",
    "\n",
    "axs[2].set_title(\"Volumetric Strain Error\")\n",
    "axs[2].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "axs[0].set_ylabel(\"Absolute Error\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# image_name = \"Drained_Strain_Control_perf_plastic_substepping_error.pdf\"\n",
    "# mcss_latex_folder = \"/home/jmoore/Documents/Master_Thesis/chapters/Constitutive_Modelling/mcss_images/perf_plastic\"\n",
    "# save_fig_path = os.path.join(mcss_latex_folder, image_name)\n",
    "# fig.savefig(save_fig_path, format = \"pdf\", bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 4, figsize = (15, 5), dpi = 300)\n",
    "\n",
    "error_names = [\"p_error\",\"q_error\", \"eps_v_error\", \"eps_q_error\"]\n",
    "\n",
    "for i, model in enumerate(OS_models):\n",
    "            # Get the model name\n",
    "    folder_name = os.path.basename(model.setup.folder_path)\n",
    "    num_iters = re.search(r'\\d+', folder_name).group()\n",
    "\n",
    "    name = f\"Ortiz-Simo  {num_iters} iters\"\n",
    "\n",
    "    # Loop over the error names\n",
    "    for j, error_name in enumerate(error_names):\n",
    "        \n",
    "        error = OS_errors[error_name][i]\n",
    " \n",
    "        # Plot the error versus the strain\n",
    "        fig.axes[j].plot(correct_model_strain[val:], error[val:], label = name, color = colors[i])\n",
    "        \n",
    "        if j ==0:\n",
    "           fig.axes[j].legend()\n",
    "\n",
    "for i, model in enumerate(Sub_models):\n",
    "            # Get the model name\n",
    "    folder_name = os.path.basename(model.setup.folder_path)\n",
    "    num_iters = re.search(r'\\d+', folder_name).group()\n",
    "\n",
    "    name = f\"Sloan-Abbo  {num_iters} iters\"\n",
    "\n",
    "    # Loop over the error names\n",
    "    for j, error_name in enumerate(error_names):\n",
    "        \n",
    "        error = Sub_errors[error_name][i]\n",
    "        \n",
    "        # Plot the error versus the strain\n",
    "        fig.axes[j].plot(correct_model_strain[val:], error[val:], label = name, \n",
    "                         color = colors[i], linestyle = \"dashed\")\n",
    "\n",
    "        if j ==0:\n",
    "           fig.axes[j].legend()\n",
    "\n",
    "# Format the plot\n",
    "# fig.suptitle(\"Index Error vs Strain\")\n",
    "axs[0].set_title(\"p error\")\n",
    "axs[0].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "axs[0].set_ylabel(\"Absolute Error\")\n",
    "\n",
    "axs[1].set_title(\"q error\")\n",
    "axs[1].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "\n",
    "axs[2].set_title(\"$\\\\epsilon_{v}$ Error\")\n",
    "axs[2].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "\n",
    "axs[3].set_title(\"$\\\\epsilon_{q}$ Error\")\n",
    "axs[3].set_xlabel(\"$\\\\epsilon_{a}$ (-)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "image_name = \"Drained_Strain_Control_plastic_dilat_index_error.pdf\"\n",
    "mcss_latex_folder = \"/home/jmoore/Documents/Master_Thesis/chapters/Constitutive_Modelling/mcss_images/plastic_dilat\"\n",
    "save_fig_path = os.path.join(mcss_latex_folder, image_name)\n",
    "fig.savefig(save_fig_path, format = \"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a figure to plot the OS models\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8, 8), dpi=300)\n",
    "\n",
    "for i, model in enumerate(OS_models):\n",
    "    folder_name = os.path.basename(model.setup.folder_path)\n",
    "    num_iters = re.search(r'\\d+', folder_name).group()\n",
    "    \n",
    "    name = f\"Ortiz-Simo  {num_iters} iters\"\n",
    "    model.results.quick_quad_plot(axial_strain_id=\"stran(1)\", compression_pos=True, axs=axs, \n",
    "                                  color=colors[i], label=name, legend=[True, False, False, False], linestyle='-', linewidth=2)\n",
    "# Add the Sloan Abbo model for comparison\n",
    "\n",
    "for i, model in enumerate(Sub_models):\n",
    "    \n",
    "    folder_name = os.path.basename(model.setup.folder_path)\n",
    "    num_iters = re.search(r'\\d+', folder_name).group()\n",
    "    \n",
    "    name = f\"Sloan-Abbo {num_iters} iters\"\n",
    "    model.results.quick_quad_plot(axial_strain_id=\"stran(1)\", compression_pos=True, axs=axs, \n",
    "                                  color=colors[i], label=name, legend=[True, False, False, False], linestyle='dashed', linewidth=2)\n",
    "    \n",
    "\n",
    "image_name = \"Drained_Strain_Control_plastic_dilat_quad.pdf\"\n",
    "mcss_latex_folder = \"/home/jmoore/Documents/Master_Thesis/chapters/Constitutive_Modelling/mcss_images/plastic_dilat\"\n",
    "save_fig_path = os.path.join(mcss_latex_folder, image_name)\n",
    "fig.savefig(save_fig_path, format = \"pdf\", bbox_inches = 'tight')\n",
    "# plt.close()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VT_Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
